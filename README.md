# ğŸ¤– Autonomous Jetson Robot

A modern ROS2 Foxy autonomous robot system with web-based control interface, designed for Jetson Nano deployment.

## âœ¨ Features

- ğŸ® **Gazebo Simulation** - Full robot simulation environment
- ğŸŒ **Modern Web Interface** - Professional control dashboard
- ğŸ¯ **ROS2 Control Integration** - Industry-standard robot control
- ğŸ“± **Mobile-Friendly** - Responsive design for all devices
- âŒ¨ï¸ **Keyboard Control** - WASD + Arrow key support
- ğŸ“Š **Real-time Monitoring** - Live metrics and system status
- ğŸ”§ **Easy Configuration** - Simple setup and deployment

## ğŸš€ Quick Start

### Prerequisites
- Docker installed and running
- Container `auto_ros_foxy` available

### Simple Commands

```bash
# Start simulation with web interface
./robot.sh sim

# Start real robot
./robot.sh robot

# Open web control interface
./robot.sh web

# Enter robot container for debugging
./robot.sh shell

# Show robot status
./robot.sh status

# Stop all robot processes
./robot.sh stop
```

## ğŸŒ Web Interface

Once running, access the robot control interface:

- **Control Dashboard**: http://localhost:8000
- **ROSBridge WebSocket**: ws://localhost:9090

### Controls
- **WASD Keys** or **Arrow Keys**: Move robot
- **Spacebar**: Emergency stop
- **Mouse/Touch**: Use on-screen D-pad
- **Sliders**: Adjust speed limits

## ğŸ“ Project Structure

```
autonomous_jetson_robot/
â”œâ”€â”€ robot.sh                    # Main control script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ my_robot_launch/        # Robot launch files & URDF
â”‚   â”œâ”€â”€ web_gui_control/        # Modern web interface
â”‚   â”œâ”€â”€ object_detection/       # Camera & object detection
â”‚   â”œâ”€â”€ mpu6050_imu/           # IMU sensor integration
â”‚   â””â”€â”€ slam_launch/           # SLAM configuration
â”œâ”€â”€ config/                     # Configuration files
â””â”€â”€ README.md                  # This file
```

## ğŸ® Usage Examples

### Start Simulation
```bash
./robot.sh sim
# Opens Gazebo + Web interface
# Control robot at http://localhost:8000
```

### Control Real Robot
```bash
./robot.sh robot
# Starts real hardware interface
# Control via web interface
```

### Debug & Development
```bash
./robot.sh shell
# Enter container for ROS development
# Full ROS2 environment available
```

## ğŸ”§ Configuration

### Robot Settings
- **Max Linear Velocity**: 1.0 m/s
- **Max Angular Velocity**: 2.0 rad/s
- **Wheel Separation**: 0.18m
- **Wheel Radius**: 0.035m
- **Encoder Resolution**: 3436 counts/rev

### Network Settings
- **Web Server**: Port 8000
- **ROSBridge**: Port 9090
- **Auto IP Detection**: Supports multiple network interfaces

## ğŸ“Š Monitoring

The web interface provides real-time monitoring:

- **Wheel RPM**: Left/Right wheel speeds
- **Velocities**: Linear and angular motion
- **System Health**: CPU, memory, battery status
- **Activity Log**: Real-time event logging
- **Connection Status**: Visual connection indicator

## ğŸ› ï¸ Development

### Build Workspace
```bash
./robot.sh build
```

### View Logs
```bash
./robot.sh logs
```

### Clean Build Files
```bash
./robot.sh clean
```

## ğŸ¯ Key Components

### ROS2 Packages
- **my_robot_launch**: Main robot launch system
- **web_gui_control**: Modern web interface
- **object_detection**: MobileNetSSD object detection
- **mpu6050_imu**: IMU sensor integration
- **slam_launch**: SLAM toolbox configuration

### Hardware Support
- **Motor Control**: TB6612FNG dual motor driver
- **Sensors**: RPLidar A1, MPU6050 IMU, Camera
- **Communication**: Micro-ROS, ROSBridge WebSocket
- **Platform**: Jetson Nano, ROS2 Foxy

## ğŸš€ Deployment

### Jetson Nano
1. Copy project to Jetson Nano
2. Run `./robot.sh robot` for real hardware
3. Access web interface from any device on network

### Development
1. Use `./robot.sh sim` for simulation testing
2. Develop and test features safely
3. Deploy to real hardware when ready

## ğŸ“ License

MIT License - Feel free to use and modify for your projects.

## ğŸ¤ Contributing

Contributions welcome! The modular architecture makes it easy to add new features:

- **New Sensors**: Add to hardware interface
- **Web Features**: Extend the modern web GUI
- **AI/ML**: Integrate with object detection
- **Navigation**: Add path planning capabilities

---

**Happy Robot Building! ğŸ¤–âœ¨**